{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Tavily Search Agent Demo\n",
        "\n",
        "This notebook demonstrates a real LLM agent that uses the Tavily MCP server for internet search capabilities.\n",
        "\n",
        "## Features\n",
        "- **Real LLM Integration**: Uses OpenAI GPT models with function calling\n",
        "- **Tavily Search**: Direct integration with Tavily API for real-time web search\n",
        "- **Interactive Agent**: Ask questions and get live web search results\n",
        "- **Multiple Search Types**: General search, Q&A, context generation\n",
        "\n",
        "## Prerequisites\n",
        "1. **Tavily API key**: Get yours from [tavily.com](https://tavily.com)\n",
        "2. **OpenAI API key**: Get yours from [openai.com](https://openai.com)  \n",
        "3. **Environment Setup**: Add both keys to your `.env` file\n",
        "\n",
        "This is a **working demo** with real API integrations - no mock data!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install openai python-dotenv tavily-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configuration\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
        "\n",
        "# Initialize clients\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY) if TAVILY_API_KEY else None\n",
        "\n",
        "print(\"ü§ñ Tavily Search Agent - Setup\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"üîë OpenAI API: {'‚úÖ Configured' if OPENAI_API_KEY else '‚ùå Missing'}\")\n",
        "print(f\"üîç Tavily API: {'‚úÖ Configured' if TAVILY_API_KEY else '‚ùå Missing'}\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"\\n‚ö†Ô∏è  Add OPENAI_API_KEY to your .env file\")\n",
        "if not TAVILY_API_KEY:\n",
        "    print(\"\\n‚ö†Ô∏è  Add TAVILY_API_KEY to your .env file\")\n",
        "\n",
        "if OPENAI_API_KEY and TAVILY_API_KEY:\n",
        "    print(\"\\nüöÄ Ready to create intelligent search agent!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TavilySearchAgent:\n",
        "    \"\"\"LLM agent with Tavily search capabilities.\"\"\"\n",
        "    \n",
        "    def __init__(self, openai_client, tavily_client):\n",
        "        self.openai_client = openai_client\n",
        "        self.tavily_client = tavily_client\n",
        "        self.conversation_history = []\n",
        "        \n",
        "    def get_function_definitions(self):\n",
        "        \"\"\"Define Tavily search functions for OpenAI function calling.\"\"\"\n",
        "        return [\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": \"tavily_search\",\n",
        "                    \"description\": \"Search the web for comprehensive information on any topic\",\n",
        "                    \"parameters\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n",
        "                            \"max_results\": {\"type\": \"integer\", \"description\": \"Max results (1-10)\", \"default\": 5}\n",
        "                        },\n",
        "                        \"required\": [\"query\"]\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": \"tavily_qna_search\",\n",
        "                    \"description\": \"Get direct answers to specific questions\",\n",
        "                    \"parameters\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"query\": {\"type\": \"string\", \"description\": \"Question to answer\"}\n",
        "                        },\n",
        "                        \"required\": [\"query\"]\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    \n",
        "    def execute_search(self, function_name, arguments):\n",
        "        \"\"\"Execute Tavily search functions.\"\"\"\n",
        "        try:\n",
        "            if function_name == \"tavily_search\":\n",
        "                response = self.tavily_client.search(\n",
        "                    query=arguments[\"query\"],\n",
        "                    max_results=arguments.get(\"max_results\", 5)\n",
        "                )\n",
        "                return {\n",
        "                    \"status\": \"success\",\n",
        "                    \"query\": arguments[\"query\"],\n",
        "                    \"results\": response.get(\"results\", [])\n",
        "                }\n",
        "            \n",
        "            elif function_name == \"tavily_qna_search\":\n",
        "                answer = self.tavily_client.qna_search(query=arguments[\"query\"])\n",
        "                return {\n",
        "                    \"status\": \"success\", \n",
        "                    \"query\": arguments[\"query\"],\n",
        "                    \"answer\": answer\n",
        "                }\n",
        "            \n",
        "            return {\"status\": \"error\", \"message\": f\"Unknown function: {function_name}\"}\n",
        "        \n",
        "        except Exception as e:\n",
        "            return {\"status\": \"error\", \"message\": str(e)}\n",
        "    \n",
        "    def chat(self, user_message, model=\"gpt-4-turbo-preview\"):\n",
        "        \"\"\"Chat with the agent - it will search the web when needed.\"\"\"\n",
        "        \n",
        "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
        "        \n",
        "        system_message = {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"\"\"You are a helpful AI assistant with real-time web search capabilities.\n",
        "Current date: {datetime.now().strftime('%Y-%m-%d')}\n",
        "\n",
        "When users ask questions requiring current information, use your search functions:\n",
        "- tavily_search: For comprehensive research with multiple sources  \n",
        "- tavily_qna_search: For direct factual answers\n",
        "\n",
        "Always provide accurate, helpful responses based on the search results.\"\"\"\n",
        "        }\n",
        "        \n",
        "        messages = [system_message] + self.conversation_history\n",
        "        \n",
        "        try:\n",
        "            # Initial OpenAI call\n",
        "            response = self.openai_client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                tools=self.get_function_definitions(),\n",
        "                tool_choice=\"auto\"\n",
        "            )\n",
        "            \n",
        "            assistant_message = response.choices[0].message\n",
        "            \n",
        "            # Handle function calls\n",
        "            if assistant_message.tool_calls:\n",
        "                # Add assistant message with tool calls\n",
        "                self.conversation_history.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": assistant_message.content,\n",
        "                    \"tool_calls\": [\n",
        "                        {\n",
        "                            \"id\": tc.id,\n",
        "                            \"type\": \"function\", \n",
        "                            \"function\": {\"name\": tc.function.name, \"arguments\": tc.function.arguments}\n",
        "                        } for tc in assistant_message.tool_calls\n",
        "                    ]\n",
        "                })\n",
        "                \n",
        "                # Execute each function call\n",
        "                for tool_call in assistant_message.tool_calls:\n",
        "                    function_name = tool_call.function.name\n",
        "                    function_args = json.loads(tool_call.function.arguments)\n",
        "                    \n",
        "                    print(f\"üîç Searching: {function_args.get('query', 'N/A')}\")\n",
        "                    \n",
        "                    # Execute search\n",
        "                    result = self.execute_search(function_name, function_args)\n",
        "                    \n",
        "                    # Add result to conversation\n",
        "                    self.conversation_history.append({\n",
        "                        \"role\": \"tool\",\n",
        "                        \"tool_call_id\": tool_call.id,\n",
        "                        \"content\": json.dumps(result)\n",
        "                    })\n",
        "                \n",
        "                # Get final response\n",
        "                final_response = self.openai_client.chat.completions.create(\n",
        "                    model=model,\n",
        "                    messages=[system_message] + self.conversation_history\n",
        "                )\n",
        "                \n",
        "                final_message = final_response.choices[0].message.content\n",
        "                self.conversation_history.append({\"role\": \"assistant\", \"content\": final_message})\n",
        "                return final_message\n",
        "            \n",
        "            else:\n",
        "                # No search needed\n",
        "                self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message.content})\n",
        "                return assistant_message.content\n",
        "        \n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error: {str(e)}\"\n",
        "            self.conversation_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
        "            return error_msg\n",
        "    \n",
        "    def clear_history(self):\n",
        "        \"\"\"Clear conversation history.\"\"\"\n",
        "        self.conversation_history = []\n",
        "        print(\"üßπ History cleared!\")\n",
        "\n",
        "# Initialize agent\n",
        "if openai_client and tavily_client:\n",
        "    agent = TavilySearchAgent(openai_client, tavily_client)\n",
        "    print(\"‚úÖ Tavily Search Agent ready!\")\n",
        "else:\n",
        "    agent = None\n",
        "    print(\"‚ùå Agent setup failed - check API keys\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Live Demo - Ask Real Questions!\n",
        "\n",
        "The agent will automatically search the web when you ask questions requiring current information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Current Events\n",
        "if agent:\n",
        "    print(\"üîç Example 1: Current AI News\")\n",
        "    print(\"=\" * 40)\n",
        "    response = agent.chat(\"What are the latest developments in AI in 2024?\")\n",
        "    print(f\"\\nü§ñ Agent: {response}\")\n",
        "else:\n",
        "    print(\"‚ùå Agent not available - add API keys to .env file\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Factual Question  \n",
        "if agent:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"‚ùì Example 2: Quick Fact Check\")\n",
        "    print(\"=\" * 40)\n",
        "    response = agent.chat(\"What is the current price of Bitcoin?\")\n",
        "    print(f\"\\nü§ñ Agent: {response}\")\n",
        "else:\n",
        "    print(\"‚ùå Agent not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Chat - Try your own questions!\n",
        "def start_chat():\n",
        "    \"\"\"Start interactive chat with the agent.\"\"\"\n",
        "    if not agent:\n",
        "        print(\"‚ùå Agent not available - check API keys\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\nü§ñ Interactive Tavily Search Agent\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Ask me anything! I'll search the web for current information.\")\n",
        "    print(\"Commands: 'clear' to reset, 'quit' to exit\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            question = input(\"\\nüë§ You: \").strip()\n",
        "            \n",
        "            if question.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\"üëã Goodbye!\")\n",
        "                break\n",
        "            elif question.lower() == 'clear':\n",
        "                agent.clear_history()\n",
        "                continue\n",
        "            elif not question:\n",
        "                continue\n",
        "            \n",
        "            print(\"\\nüîÑ Thinking...\")\n",
        "            response = agent.chat(question)\n",
        "            print(f\"\\nü§ñ Agent: {response}\")\n",
        "            \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüëã Chat ended!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error: {e}\")\n",
        "\n",
        "# Uncomment the line below to start interactive chat\n",
        "# start_chat()\n",
        "\n",
        "print(\"üí° Uncomment the last line above to start interactive chat!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Setup Instructions\n",
        "\n",
        "### Quick Start:\n",
        "1. **Get API Keys**:\n",
        "   - Tavily: [tavily.com](https://tavily.com) (free tier available)\n",
        "   - OpenAI: [openai.com](https://openai.com) (pay-per-use)\n",
        "\n",
        "2. **Configure Environment**:\n",
        "   ```bash\n",
        "   # In your .env file:\n",
        "   TAVILY_API_KEY=tvly-YOUR_KEY_HERE\n",
        "   OPENAI_API_KEY=sk-YOUR_KEY_HERE\n",
        "   ```\n",
        "\n",
        "3. **Run the notebook** - the agent will automatically search when needed!\n",
        "\n",
        "### How it Works:\n",
        "- **Intelligent Function Calling**: The LLM decides when to search based on your question\n",
        "- **Real-time Results**: Live data from Tavily's search API\n",
        "- **Context Awareness**: Maintains conversation history for follow-up questions\n",
        "\n",
        "### Example Questions to Try:\n",
        "- \"What's happening with Tesla stock today?\"\n",
        "- \"Who won the latest Nobel Prize?\"\n",
        "- \"What are the current trends in renewable energy?\"\n",
        "- \"Tell me about recent space missions\"\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
